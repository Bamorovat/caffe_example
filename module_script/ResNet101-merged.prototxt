name: "ResNet-101"
input: "data"
#half_precision_mode: HALF_ALL
input_dim: 1
input_dim: 3
input_dim: 224
input_dim: 224

layer {
	bottom: "data"
	top: "conv1"
	name: "conv1"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_RELU
		num_output: 64
		kernel_size: 7
		pad: 3
		stride: 2
		bias_term: false
	}
}


layer {
	bottom: "conv1"
	top: "pool1"
	name: "pool1"
	type: "Pooling"
	pooling_param {
		kernel_size: 3
		stride: 2
		pool: MAX
	}
}

layer {
	bottom: "pool1"
	top: "res2a_branch1"
	name: "res2a_branch1"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "pool1"
	top: "res2a_branch2a"
	name: "res2a_branch2a"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_RELU
		num_output: 64
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}


layer {
	bottom: "res2a_branch2a"
	top: "res2a_branch2b"
	name: "res2a_branch2b"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_RELU
		num_output: 64
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res2a_branch2b"
	bottom: "res2a_branch1"
	top: "res2a"
	name: "res2a_branch2c"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_ELTWISE_RELU
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res2a"
	top: "res2b_branch2a"
	name: "res2b_branch2a"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_RELU
		num_output: 64
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res2b_branch2a"
	top: "res2b_branch2b"
	name: "res2b_branch2b"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_RELU
		num_output: 64
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res2b_branch2b"
	bottom: "res2a"
	top: "res2b"
	name: "res2b_branch2c"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_ELTWISE_RELU
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res2b"
	top: "res2c_branch2a"
	name: "res2c_branch2a"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_RELU
		num_output: 64
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res2c_branch2a"
	top: "res2c_branch2b"
	name: "res2c_branch2b"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_RELU
		num_output: 64
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res2c_branch2b"
	bottom: "res2b"
	top: "res2c"
	name: "res2c_branch2c"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_ELTWISE_RELU
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res2c"
	top: "res3a_branch1"
	name: "res3a_branch1"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 1
		pad: 0
		stride: 2
		bias_term: false
	}
}

layer {
	bottom: "res2c"
	top: "res3a_branch2a"
	name: "res3a_branch2a"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_RELU
		num_output: 128
		kernel_size: 1
		pad: 0
		stride: 2
		bias_term: false
	}
}

layer {
	bottom: "res3a_branch2a"
	top: "res3a_branch2b"
	name: "res3a_branch2b"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_RELU
		num_output: 128
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res3a_branch2b"
	bottom: "res3a_branch1"
	top: "res3a"
	name: "res3a_branch2c"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_ELTWISE_RELU
		num_output: 512
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res3a"
	top: "res3b1_branch2a"
	name: "res3b1_branch2a"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_RELU
		num_output: 128
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res3b1_branch2a"
	top: "res3b1_branch2b"
	name: "res3b1_branch2b"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_RELU
		num_output: 128
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res3b1_branch2b"
	bottom: "res3a"
	top: "res3b1"
	name: "res3b1_branch2c"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_ELTWISE_RELU
		num_output: 512
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res3b1"
	top: "res3b2_branch2a"
	name: "res3b2_branch2a"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_RELU
		num_output: 128
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res3b2_branch2a"
	top: "res3b2_branch2b"
	name: "res3b2_branch2b"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_RELU
		num_output: 128
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res3b2_branch2b"
	bottom: "res3b1"
	top: "res3b2"
	name: "res3b2_branch2c"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_ELTWISE_RELU
		num_output: 512
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res3b2"
	top: "res3b3_branch2a"
	name: "res3b3_branch2a"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_RELU
		num_output: 128
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res3b3_branch2a"
	top: "res3b3_branch2b"
	name: "res3b3_branch2b"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_RELU
		num_output: 128
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res3b3_branch2b"
	bottom: "res3b2"
	top: "res3b3"
	name: "res3b3_branch2c"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_ELTWISE_RELU
		num_output: 512
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res3b3"
	top: "res4a_branch1"
	name: "res4a_branch1"
	type: "Convolution"
	convolution_param {
		num_output: 1024
		kernel_size: 1
		pad: 0
		stride: 2
		bias_term: false
	}
}

layer {
	bottom: "res3b3"
	top: "res4a_branch2a"
	name: "res4a_branch2a"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_RELU
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 2
		bias_term: false
	}
}

layer {
	bottom: "res4a_branch2a"
	top: "res4a_branch2b"
	name: "res4a_branch2b"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_RELU
		num_output: 256
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4a_branch2b"
	bottom: "res4a_branch1"
	top: "res4a"
	name: "res4a_branch2c"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_ELTWISE_RELU
		num_output: 1024
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4a"
	top: "res4b1_branch2a"
	name: "res4b1_branch2a"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_RELU
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b1_branch2a"
	top: "res4b1_branch2b"
	name: "res4b1_branch2b"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_RELU
		num_output: 256
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b1_branch2b"
	bottom: "res4a"
	top: "res4b1"
	name: "res4b1_branch2c"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_ELTWISE_RELU
		num_output: 1024
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b1"
	top: "res4b2_branch2a"
	name: "res4b2_branch2a"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_RELU
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b2_branch2a"
	top: "res4b2_branch2b"
	name: "res4b2_branch2b"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_RELU
		num_output: 256
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b2_branch2b"
	bottom: "res4b1"
	top: "res4b2"
	name: "res4b2_branch2c"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_ELTWISE_RELU
		num_output: 1024
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b2"
	top: "res4b3_branch2a"
	name: "res4b3_branch2a"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_RELU
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b3_branch2a"
	top: "res4b3_branch2b"
	name: "res4b3_branch2b"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_RELU
		num_output: 256
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b3_branch2b"
	bottom: "res4b2"
	top: "res4b3"
	name: "res4b3_branch2c"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_ELTWISE_RELU
		num_output: 1024
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b3"
	top: "res4b4_branch2a"
	name: "res4b4_branch2a"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_RELU
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b4_branch2a"
	top: "res4b4_branch2b"
	name: "res4b4_branch2b"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_RELU
		num_output: 256
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b4_branch2b"
	bottom: "res4b3"
	top: "res4b4"
	name: "res4b4_branch2c"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_ELTWISE_RELU
		num_output: 1024
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b4"
	top: "res4b5_branch2a"
	name: "res4b5_branch2a"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_RELU
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b5_branch2a"
	top: "res4b5_branch2b"
	name: "res4b5_branch2b"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_RELU
		num_output: 256
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b5_branch2b"
	bottom: "res4b4"
	top: "res4b5"
	name: "res4b5_branch2c"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_ELTWISE_RELU
		num_output: 1024
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b5"
	top: "res4b6_branch2a"
	name: "res4b6_branch2a"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_RELU
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b6_branch2a"
	top: "res4b6_branch2b"
	name: "res4b6_branch2b"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_RELU
		num_output: 256
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b6_branch2b"
	bottom: "res4b5"
	top: "res4b6"
	name: "res4b6_branch2c"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_ELTWISE_RELU
		num_output: 1024
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b6"
	top: "res4b7_branch2a"
	name: "res4b7_branch2a"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_RELU
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b7_branch2a"
	top: "res4b7_branch2b"
	name: "res4b7_branch2b"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_RELU
		num_output: 256
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b7_branch2b"
	bottom: "res4b6"
	top: "res4b7"
	name: "res4b7_branch2c"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_ELTWISE_RELU
		num_output: 1024
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}


layer {
	bottom: "res4b7"
	top: "res4b8_branch2a"
	name: "res4b8_branch2a"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_RELU
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b8_branch2a"
	top: "res4b8_branch2b"
	name: "res4b8_branch2b"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_RELU
		num_output: 256
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b8_branch2b"
	bottom: "res4b7"
	top: "res4b8"
	name: "res4b8_branch2c"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_ELTWISE_RELU
		num_output: 1024
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b8"
	top: "res4b9_branch2a"
	name: "res4b9_branch2a"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_RELU
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b9_branch2a"
	top: "res4b9_branch2b"
	name: "res4b9_branch2b"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_RELU
		num_output: 256
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b9_branch2b"
	bottom: "res4b8"
	top: "res4b9"
	name: "res4b9_branch2c"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_ELTWISE_RELU
		num_output: 1024
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b9"
	top: "res4b10_branch2a"
	name: "res4b10_branch2a"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_RELU
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b10_branch2a"
	top: "res4b10_branch2b"
	name: "res4b10_branch2b"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_RELU
		num_output: 256
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b10_branch2b"
	bottom: "res4b9"
	top: "res4b10"
	name: "res4b10_branch2c"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_ELTWISE_RELU
		num_output: 1024
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b10"
	top: "res4b11_branch2a"
	name: "res4b11_branch2a"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_RELU
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b11_branch2a"
	top: "res4b11_branch2b"
	name: "res4b11_branch2b"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_RELU
		num_output: 256
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b11_branch2b"
	bottom: "res4b10"
	top: "res4b11"
	name: "res4b11_branch2c"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_ELTWISE_RELU
		num_output: 1024
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b11"
	top: "res4b12_branch2a"
	name: "res4b12_branch2a"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_RELU
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b12_branch2a"
	top: "res4b12_branch2b"
	name: "res4b12_branch2b"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_RELU
		num_output: 256
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b12_branch2b"
	bottom: "res4b11"
	top: "res4b12"
	name: "res4b12_branch2c"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_ELTWISE_RELU
		num_output: 1024
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b12"
	top: "res4b13_branch2a"
	name: "res4b13_branch2a"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_RELU
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b13_branch2a"
	top: "res4b13_branch2b"
	name: "res4b13_branch2b"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_RELU
		num_output: 256
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b13_branch2b"
	bottom: "res4b12"
	top: "res4b13"
	name: "res4b13_branch2c"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_ELTWISE_RELU
		num_output: 1024
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b13"
	top: "res4b14_branch2a"
	name: "res4b14_branch2a"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_RELU
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b14_branch2a"
	top: "res4b14_branch2b"
	name: "res4b14_branch2b"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_RELU
		num_output: 256
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b14_branch2b"
	bottom: "res4b13"
	top: "res4b14"
	name: "res4b14_branch2c"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_ELTWISE_RELU
		num_output: 1024
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b14"
	top: "res4b15_branch2a"
	name: "res4b15_branch2a"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_RELU
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b15_branch2a"
	top: "res4b15_branch2b"
	name: "res4b15_branch2b"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_RELU
		num_output: 256
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b15_branch2b"
	bottom: "res4b14"
	top: "res4b15"
	name: "res4b15_branch2c"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_ELTWISE_RELU
		num_output: 1024
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b15"
	top: "res4b16_branch2a"
	name: "res4b16_branch2a"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_RELU
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b16_branch2a"
	top: "res4b16_branch2b"
	name: "res4b16_branch2b"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_RELU
		num_output: 256
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b16_branch2b"
	bottom: "res4b15"
	top: "res4b16"
	name: "res4b16_branch2c"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_ELTWISE_RELU
		num_output: 1024
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b16"
	top: "res4b17_branch2a"
	name: "res4b17_branch2a"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_RELU
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b17_branch2a"
	top: "res4b17_branch2b"
	name: "res4b17_branch2b"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_RELU
		num_output: 256
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b17_branch2b"
	bottom: "res4b16"
	top: "res4b17"
	name: "res4b17_branch2c"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_ELTWISE_RELU
		num_output: 1024
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b17"
	top: "res4b18_branch2a"
	name: "res4b18_branch2a"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_RELU
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b18_branch2a"
	top: "res4b18_branch2b"
	name: "res4b18_branch2b"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_RELU
		num_output: 256
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b18_branch2b"
	bottom: "res4b17"
	top: "res4b18"
	name: "res4b18_branch2c"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_ELTWISE_RELU
		num_output: 1024
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b18"
	top: "res4b19_branch2a"
	name: "res4b19_branch2a"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_RELU
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b19_branch2a"
	top: "res4b19_branch2b"
	name: "res4b19_branch2b"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_RELU
		num_output: 256
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b19_branch2b"
	bottom: "res4b18"
	top: "res4b19"
	name: "res4b19_branch2c"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_ELTWISE_RELU
		num_output: 1024
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b19"
	top: "res4b20_branch2a"
	name: "res4b20_branch2a"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_RELU
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b20_branch2a"
	top: "res4b20_branch2b"
	name: "res4b20_branch2b"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_RELU
		num_output: 256
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b20_branch2b"
	bottom: "res4b19"
	top: "res4b20"
	name: "res4b20_branch2c"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_ELTWISE_RELU
		num_output: 1024
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b20"
	top: "res4b21_branch2a"
	name: "res4b21_branch2a"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_RELU
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b21_branch2a"
	top: "res4b21_branch2b"
	name: "res4b21_branch2b"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_RELU
		num_output: 256
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b21_branch2b"
	bottom: "res4b20"
	top: "res4b21"
	name: "res4b21_branch2c"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_ELTWISE_RELU
		num_output: 1024
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b21"
	top: "res4b22_branch2a"
	name: "res4b22_branch2a"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_RELU
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b22_branch2a"
	top: "res4b22_branch2b"
	name: "res4b22_branch2b"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_RELU
		num_output: 256
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b22_branch2b"
	bottom: "res4b21"
	top: "res4b22"
	name: "res4b22_branch2c"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_ELTWISE_RELU
		num_output: 1024
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res4b22"
	top: "res5a_branch1"
	name: "res5a_branch1"
	type: "Convolution"
	convolution_param {
		num_output: 2048
		kernel_size: 1
		pad: 0
		stride: 2
		bias_term: false
	}
}

layer {
	bottom: "res4b22"
	top: "res5a_branch2a"
	name: "res5a_branch2a"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_RELU
		num_output: 512
		kernel_size: 1
		pad: 0
		stride: 2
		bias_term: false
	}
}

layer {
	bottom: "res5a_branch2a"
	top: "res5a_branch2b"
	name: "res5a_branch2b"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_RELU
		num_output: 512
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res5a_branch2b"
	bottom: "res5a_branch1"
	top: "res5a"
	name: "res5a_branch2c"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_ELTWISE_RELU
		num_output: 2048
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res5a"
	top: "res5b_branch2a"
	name: "res5b_branch2a"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_RELU
		num_output: 512
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res5b_branch2a"
	top: "res5b_branch2b"
	name: "res5b_branch2b"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_RELU
		num_output: 512
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res5b_branch2b"
	bottom: "res5a"
	top: "res5b"
	name: "res5b_branch2c"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_ELTWISE_RELU
		num_output: 2048
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res5b"
	top: "res5c_branch2a"
	name: "res5c_branch2a"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_RELU
		num_output: 512
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res5c_branch2a"
	top: "res5c_branch2b"
	name: "res5c_branch2b"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_RELU
		num_output: 512
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res5c_branch2b"
	bottom: "res5b"
	top: "res5c"
	name: "res5c_branch2c"
	type: "Convolution"
	convolution_param {
	        fuse_type: FUSED_CONV_ELTWISE_RELU
		num_output: 2048
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "res5c"
	top: "pool5"
	name: "pool5"
	type: "Pooling"
	pooling_param {
		kernel_size: 7
		stride: 1
		pool: AVE
	}
}

layer {
	bottom: "pool5"
	top: "fc1000"
	name: "fc1000"
	type: "InnerProduct"
	inner_product_param {
		num_output: 1000
	}
}

layer {
	bottom: "fc1000"
	top: "prob"
	name: "prob"
	type: "Softmax"
}

